{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8035e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d880e064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  6.9087e-01,  7.2297e-01,  5.4945e-01,\n",
       "          8.3552e-01,  4.2926e-01,  9.0318e-01,  3.3196e-01,  9.4329e-01,\n",
       "          2.5523e-01,  9.6688e-01,  1.9557e-01,  9.8069e-01,  1.4957e-01,\n",
       "          9.8875e-01,  1.1425e-01,  9.9345e-01,  8.7222e-02,  9.9619e-01,\n",
       "          6.6559e-02,  9.9778e-01,  5.0780e-02,  9.9871e-01,  3.8737e-02,\n",
       "          9.9925e-01,  2.9548e-02,  9.9956e-01,  2.2537e-02,  9.9975e-01,\n",
       "          1.7190e-02,  9.9985e-01,  1.3111e-02,  9.9991e-01,  9.9998e-03,\n",
       "          9.9995e-01,  7.6269e-03,  9.9997e-01,  5.8171e-03,  9.9998e-01,\n",
       "          4.4367e-03,  9.9999e-01,  3.3838e-03,  9.9999e-01,  2.5809e-03,\n",
       "          1.0000e+00,  1.9684e-03,  1.0000e+00,  1.5013e-03,  1.0000e+00,\n",
       "          1.1450e-03,  1.0000e+00,  8.7333e-04,  1.0000e+00,  6.6608e-04,\n",
       "          1.0000e+00,  5.0802e-04,  1.0000e+00,  3.8747e-04,  1.0000e+00,\n",
       "          2.9552e-04,  1.0000e+00,  2.2539e-04,  1.0000e+00,  1.7191e-04,\n",
       "          1.0000e+00,  1.3111e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.9897e-01,  4.5384e-02,  9.1816e-01,\n",
       "          3.9620e-01,  7.7539e-01,  6.3148e-01,  6.2628e-01,  7.7960e-01,\n",
       "          4.9355e-01,  8.6971e-01,  3.8359e-01,  9.2350e-01,  2.9577e-01,\n",
       "          9.5526e-01,  2.2701e-01,  9.7389e-01,  1.7378e-01,  9.8478e-01,\n",
       "          1.3282e-01,  9.9114e-01,  1.0143e-01,  9.9484e-01,  7.7416e-02,\n",
       "          9.9700e-01,  5.9070e-02,  9.9825e-01,  4.5063e-02,  9.9898e-01,\n",
       "          3.4375e-02,  9.9941e-01,  2.6220e-02,  9.9966e-01,  1.9999e-02,\n",
       "          9.9980e-01,  1.5253e-02,  9.9988e-01,  1.1634e-02,  9.9993e-01,\n",
       "          8.8733e-03,  9.9996e-01,  6.7677e-03,  9.9998e-01,  5.1617e-03,\n",
       "          9.9999e-01,  3.9368e-03,  9.9999e-01,  3.0026e-03,  1.0000e+00,\n",
       "          2.2901e-03,  1.0000e+00,  1.7467e-03,  1.0000e+00,  1.3322e-03,\n",
       "          1.0000e+00,  1.0160e-03,  1.0000e+00,  7.7493e-04,  1.0000e+00,\n",
       "          5.9104e-04,  1.0000e+00,  4.5079e-04,  1.0000e+00,  3.4381e-04,\n",
       "          1.0000e+00,  2.6223e-04,  1.0000e+00],\n",
       "        [ 1.4112e-01, -9.8999e-01,  7.5358e-01, -6.5735e-01,  9.8484e-01,\n",
       "         -1.7345e-01,  9.7139e-01,  2.3750e-01,  8.4956e-01,  5.2749e-01,\n",
       "          6.9919e-01,  7.1494e-01,  5.5680e-01,  8.3065e-01,  4.3532e-01,\n",
       "          9.0028e-01,  3.3680e-01,  9.4158e-01,  2.5901e-01,  9.6587e-01,\n",
       "          1.9850e-01,  9.8010e-01,  1.5182e-01,  9.8841e-01,  1.1598e-01,\n",
       "          9.9325e-01,  8.8540e-02,  9.9607e-01,  6.7566e-02,  9.9771e-01,\n",
       "          5.1549e-02,  9.9867e-01,  3.9324e-02,  9.9923e-01,  2.9995e-02,\n",
       "          9.9955e-01,  2.2879e-02,  9.9974e-01,  1.7450e-02,  9.9985e-01,\n",
       "          1.3310e-02,  9.9991e-01,  1.0151e-02,  9.9995e-01,  7.7425e-03,\n",
       "          9.9997e-01,  5.9052e-03,  9.9998e-01,  4.5039e-03,  9.9999e-01,\n",
       "          3.4351e-03,  9.9999e-01,  2.6200e-03,  1.0000e+00,  1.9983e-03,\n",
       "          1.0000e+00,  1.5241e-03,  1.0000e+00,  1.1624e-03,  1.0000e+00,\n",
       "          8.8656e-04,  1.0000e+00,  6.7618e-04,  1.0000e+00,  5.1572e-04,\n",
       "          1.0000e+00,  3.9334e-04,  1.0000e+00],\n",
       "        [-7.5680e-01, -6.5364e-01,  9.0674e-02, -9.9588e-01,  7.2756e-01,\n",
       "         -6.8605e-01,  9.7929e-01, -2.0247e-01,  9.7649e-01,  2.1555e-01,\n",
       "          8.5850e-01,  5.1281e-01,  7.0850e-01,  7.0571e-01,  5.6508e-01,\n",
       "          8.2504e-01,  4.4217e-01,  8.9693e-01,  3.4227e-01,  9.3960e-01,\n",
       "          2.6329e-01,  9.6472e-01,  2.0181e-01,  9.7942e-01,  1.5437e-01,\n",
       "          9.8801e-01,  1.1793e-01,  9.9302e-01,  9.0035e-02,  9.9594e-01,\n",
       "          6.8709e-02,  9.9764e-01,  5.2421e-02,  9.9863e-01,  3.9989e-02,\n",
       "          9.9920e-01,  3.0503e-02,  9.9953e-01,  2.3266e-02,  9.9973e-01,\n",
       "          1.7746e-02,  9.9984e-01,  1.3535e-02,  9.9991e-01,  1.0323e-02,\n",
       "          9.9995e-01,  7.8736e-03,  9.9997e-01,  6.0052e-03,  9.9998e-01,\n",
       "          4.5802e-03,  9.9999e-01,  3.4933e-03,  9.9999e-01,  2.6643e-03,\n",
       "          1.0000e+00,  2.0321e-03,  1.0000e+00,  1.5499e-03,  1.0000e+00,\n",
       "          1.1821e-03,  1.0000e+00,  9.0157e-04,  1.0000e+00,  6.8763e-04,\n",
       "          1.0000e+00,  5.2445e-04,  1.0000e+00],\n",
       "        [-9.5892e-01,  2.8366e-01, -6.2247e-01, -7.8264e-01,  2.3094e-01,\n",
       "         -9.7297e-01,  7.9757e-01, -6.0323e-01,  9.9267e-01, -1.2084e-01,\n",
       "          9.6095e-01,  2.7671e-01,  8.3283e-01,  5.5352e-01,  6.8212e-01,\n",
       "          7.3124e-01,  5.4176e-01,  8.4054e-01,  4.2292e-01,  9.0617e-01,\n",
       "          3.2692e-01,  9.4505e-01,  2.5129e-01,  9.6791e-01,  1.9252e-01,\n",
       "          9.8129e-01,  1.4722e-01,  9.8910e-01,  1.1246e-01,  9.9366e-01,\n",
       "          8.5848e-02,  9.9631e-01,  6.5510e-02,  9.9785e-01,  4.9979e-02,\n",
       "          9.9875e-01,  3.8126e-02,  9.9927e-01,  2.9081e-02,  9.9958e-01,\n",
       "          2.2182e-02,  9.9975e-01,  1.6918e-02,  9.9986e-01,  1.2904e-02,\n",
       "          9.9992e-01,  9.8419e-03,  9.9995e-01,  7.5065e-03,  9.9997e-01,\n",
       "          5.7252e-03,  9.9998e-01,  4.3666e-03,  9.9999e-01,  3.3304e-03,\n",
       "          9.9999e-01,  2.5401e-03,  1.0000e+00,  1.9373e-03,  1.0000e+00,\n",
       "          1.4776e-03,  1.0000e+00,  1.1270e-03,  1.0000e+00,  8.5954e-04,\n",
       "          1.0000e+00,  6.5557e-04,  1.0000e+00],\n",
       "        [-2.7942e-01,  9.6017e-01, -9.9074e-01, -1.3578e-01, -3.4164e-01,\n",
       "         -9.3983e-01,  4.6141e-01, -8.8719e-01,  8.9627e-01, -4.4351e-01,\n",
       "          9.9975e-01,  2.2278e-02,  9.2501e-01,  3.7995e-01,  7.8382e-01,\n",
       "          6.2099e-01,  6.3424e-01,  7.7313e-01,  5.0034e-01,  8.6583e-01,\n",
       "          3.8910e-01,  9.2120e-01,  3.0011e-01,  9.5390e-01,  2.3039e-01,\n",
       "          9.7310e-01,  1.7638e-01,  9.8432e-01,  1.3482e-01,  9.9087e-01,\n",
       "          1.0296e-01,  9.9469e-01,  7.8587e-02,  9.9691e-01,  5.9964e-02,\n",
       "          9.9820e-01,  4.5746e-02,  9.9895e-01,  3.4895e-02,  9.9939e-01,\n",
       "          2.6617e-02,  9.9965e-01,  2.0302e-02,  9.9979e-01,  1.5485e-02,\n",
       "          9.9988e-01,  1.1810e-02,  9.9993e-01,  9.0077e-03,  9.9996e-01,\n",
       "          6.8702e-03,  9.9998e-01,  5.2399e-03,  9.9999e-01,  3.9965e-03,\n",
       "          9.9999e-01,  3.0481e-03,  1.0000e+00,  2.3248e-03,  1.0000e+00,\n",
       "          1.7731e-03,  1.0000e+00,  1.3524e-03,  1.0000e+00,  1.0314e-03,\n",
       "          1.0000e+00,  7.8668e-04,  1.0000e+00],\n",
       "        [ 6.5699e-01,  7.5390e-01, -8.1008e-01,  5.8631e-01, -8.0184e-01,\n",
       "         -5.9754e-01,  3.5904e-02, -9.9936e-01,  6.9821e-01, -7.1589e-01,\n",
       "          9.7233e-01, -2.3363e-01,  9.8145e-01,  1.9171e-01,  8.6788e-01,\n",
       "          4.9677e-01,  7.1842e-01,  6.9561e-01,  5.7396e-01,  8.1889e-01,\n",
       "          4.4955e-01,  8.9326e-01,  3.4817e-01,  9.3743e-01,  2.6791e-01,\n",
       "          9.6344e-01,  2.0539e-01,  9.7868e-01,  1.5712e-01,  9.8758e-01,\n",
       "          1.2004e-01,  9.9277e-01,  9.1651e-02,  9.9579e-01,  6.9943e-02,\n",
       "          9.9755e-01,  5.3364e-02,  9.9858e-01,  4.0708e-02,  9.9917e-01,\n",
       "          3.1052e-02,  9.9952e-01,  2.3685e-02,  9.9972e-01,  1.8065e-02,\n",
       "          9.9984e-01,  1.3778e-02,  9.9991e-01,  1.0509e-02,  9.9994e-01,\n",
       "          8.0152e-03,  9.9997e-01,  6.1132e-03,  9.9998e-01,  4.6626e-03,\n",
       "          9.9999e-01,  3.5561e-03,  9.9999e-01,  2.7123e-03,  1.0000e+00,\n",
       "          2.0686e-03,  1.0000e+00,  1.5778e-03,  1.0000e+00,  1.2033e-03,\n",
       "          1.0000e+00,  9.1779e-04,  1.0000e+00],\n",
       "        [ 9.8936e-01, -1.4550e-01, -1.8060e-01,  9.8356e-01, -9.9828e-01,\n",
       "         -5.8683e-02, -3.9655e-01, -9.1801e-01,  4.2096e-01, -9.0708e-01,\n",
       "          8.8049e-01, -4.7406e-01,  9.9999e-01, -3.9392e-03,  9.3242e-01,\n",
       "          3.6138e-01,  7.9320e-01,  6.0897e-01,  6.4319e-01,  7.6570e-01,\n",
       "          5.0801e-01,  8.6135e-01,  3.9532e-01,  9.1854e-01,  3.0503e-01,\n",
       "          9.5234e-01,  2.3422e-01,  9.7218e-01,  1.7934e-01,  9.8379e-01,\n",
       "          1.3709e-01,  9.9056e-01,  1.0470e-01,  9.9450e-01,  7.9915e-02,\n",
       "          9.9680e-01,  6.0978e-02,  9.9814e-01,  4.6520e-02,  9.9892e-01,\n",
       "          3.5486e-02,  9.9937e-01,  2.7068e-02,  9.9963e-01,  2.0645e-02,\n",
       "          9.9979e-01,  1.5747e-02,  9.9988e-01,  1.2010e-02,  9.9993e-01,\n",
       "          9.1603e-03,  9.9996e-01,  6.9866e-03,  9.9998e-01,  5.3287e-03,\n",
       "          9.9999e-01,  4.0642e-03,  9.9999e-01,  3.0997e-03,  1.0000e+00,\n",
       "          2.3642e-03,  1.0000e+00,  1.8031e-03,  1.0000e+00,  1.3753e-03,\n",
       "          1.0000e+00,  1.0489e-03,  1.0000e+00],\n",
       "        [ 4.1212e-01, -9.1113e-01,  5.4895e-01,  8.3586e-01, -8.6633e-01,\n",
       "          4.9947e-01, -7.5222e-01, -6.5891e-01,  9.5975e-02, -9.9538e-01,\n",
       "          7.3034e-01, -6.8309e-01,  9.7991e-01, -1.9943e-01,  9.7598e-01,\n",
       "          2.1786e-01,  8.5758e-01,  5.1435e-01,  7.0753e-01,  7.0669e-01,\n",
       "          5.6421e-01,  8.2563e-01,  4.4146e-01,  8.9728e-01,  3.4170e-01,\n",
       "          9.3981e-01,  2.6284e-01,  9.6484e-01,  2.0147e-01,  9.7950e-01,\n",
       "          1.5410e-01,  9.8806e-01,  1.1773e-01,  9.9305e-01,  8.9879e-02,\n",
       "          9.9595e-01,  6.8589e-02,  9.9765e-01,  5.2330e-02,  9.9863e-01,\n",
       "          3.9920e-02,  9.9920e-01,  3.0450e-02,  9.9954e-01,  2.3226e-02,\n",
       "          9.9973e-01,  1.7715e-02,  9.9984e-01,  1.3511e-02,  9.9991e-01,\n",
       "          1.0305e-02,  9.9995e-01,  7.8599e-03,  9.9997e-01,  5.9947e-03,\n",
       "          9.9998e-01,  4.5722e-03,  9.9999e-01,  3.4872e-03,  9.9999e-01,\n",
       "          2.6597e-03,  1.0000e+00,  2.0285e-03,  1.0000e+00,  1.5472e-03,\n",
       "          1.0000e+00,  1.1800e-03,  1.0000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding = torch.zeros(10, 68)\n",
    "positions_list = torch.arange(0, 10, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5  10,1\n",
    "division_term = torch.exp(torch.arange(0, 68, 2).float() * (-math.log(10000.0)) / 68) # 1000^(2i/dim_model)\n",
    "        \n",
    "# PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "# PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dac661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5  10,1\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acdb9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56dfb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2., 1., 1., 1., 1., 1., 1., 1., 1., 3.]), array([2., 1., 1., 1., 1., 1., 1., 1., 1., 3.])]\n",
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "def generate_random_data(n):\n",
    "    SOS_token = np.array([2])\n",
    "    EOS_token = np.array([3])\n",
    "    length = 8\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 0,0,0,0 -> 0,0,0,0\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 1,0,1,0 -> 1,0,1,0,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.zeros(length)\n",
    "        start = random.randint(0, 1)\n",
    "\n",
    "        X[start::2] = 1\n",
    "\n",
    "        y = np.zeros(length)\n",
    "        if X[-1] == 0:\n",
    "            y[::2] = 1\n",
    "        else:\n",
    "            y[1::2] = 1\n",
    "\n",
    "        X = np.concatenate((SOS_token, X, EOS_token))\n",
    "        y = np.concatenate((SOS_token, y, EOS_token))\n",
    "\n",
    "        data.append([X, y])\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            # Here you would need to get the max length of the batch,\n",
    "            # and normalize the length with the PAD token.\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "\n",
    "                # Get longest sentence in batch\n",
    "                for seq in data[idx : idx + batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "\n",
    "                # Append X padding tokens until it reaches the max length\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
    "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
    "\n",
    "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_data = generate_random_data(9000)\n",
    "val_data = generate_random_data(3000)\n",
    "print(train_data[0])\n",
    "train_dataloader = batchify_data(train_data)\n",
    "val_dataloader = batchify_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7a2a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TokenEmbedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# LAYERS\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoder \u001b[38;5;241m=\u001b[39m PositionalEncoding(\n\u001b[0;32m     24\u001b[0m     dim_model\u001b[38;5;241m=\u001b[39mdim_model, dropout_p\u001b[38;5;241m=\u001b[39mdropout_p, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_tok_emb \u001b[38;5;241m=\u001b[39m \u001b[43mTokenEmbedding\u001b[49m(num_tokens, emb_size)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer(\n\u001b[0;32m     28\u001b[0m     d_model\u001b[38;5;241m=\u001b[39mdim_model,\n\u001b[0;32m     29\u001b[0m     nhead\u001b[38;5;241m=\u001b[39mnum_heads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     dropout\u001b[38;5;241m=\u001b[39mdropout_p,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(dim_model, num_tokens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TokenEmbedding' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ebda84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 3]\n",
      " [1 1 1 1 1 1 1 1 3]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [1 0 1 0 1 0 1 0 3]\n",
      " [0 1 0 1 0 1 0 1 3]\n",
      " [1 1 1 1 1 1 1 1 3]\n",
      " [1 1 1 1 1 1 1 1 3]\n",
      " [0 1 0 1 0 1 0 1 3]\n",
      " [1 1 1 1 1 1 1 1 3]\n",
      " [1 0 1 0 1 0 1 0 3]\n",
      " [1 0 1 0 1 0 1 0 3]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3]]\n",
      "[[2 0 0 0 0 0 0 0 0 3]\n",
      " [2 1 1 1 1 1 1 1 1 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]\n",
      " [2 1 0 1 0 1 0 1 0 3]\n",
      " [2 0 1 0 1 0 1 0 1 3]\n",
      " [2 1 1 1 1 1 1 1 1 3]\n",
      " [2 1 1 1 1 1 1 1 1 3]\n",
      " [2 0 1 0 1 0 1 0 1 3]\n",
      " [2 1 1 1 1 1 1 1 1 3]\n",
      " [2 1 0 1 0 1 0 1 0 3]\n",
      " [2 1 0 1 0 1 0 1 0 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]\n",
      " [2 0 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "batch = train_dataloader[0]\n",
    "y = batch[:,1]\n",
    "y_input = y[:,1:]\n",
    "print(y_input)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c5a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        print(X.shape, y.shape)\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        print(y_input.shape, y_expected.shape)\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y_expected)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dbdb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[:, 0], batch[:, 1]\n",
    "            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f02ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n",
      "(16, 10) (16, 10)\n",
      "torch.Size([16, 9]) torch.Size([16, 9])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss_list, validation_loss_list\n\u001b[1;32m---> 26\u001b[0m train_loss_list, validation_loss_list \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, opt, loss_fn, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     train_loss_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [train_loss]\n\u001b[0;32m     17\u001b[0m     validation_loss \u001b[38;5;241m=\u001b[39m validation_loop(model, loss_fn, val_dataloader)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, opt, loss_fn, dataloader)\u001b[0m\n\u001b[0;32m     28\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)      \n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y_expected)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     33\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch10\\lib\\site-packages\\torch\\optim\\optimizer.py:222\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    220\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m foreach \u001b[38;5;129;01mor\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse):\n\u001b[1;32m--> 222\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     per_device_and_dtype_grads[p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdevice][p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype]\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6cd984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "Example 0\n",
      "Input: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "torch.Size([1, 1])\n",
      "Example 1\n",
      "Input: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "torch.Size([1, 1])\n",
      "Example 2\n",
      "Input: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n",
      "torch.Size([1, 1])\n",
      "Example 3\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n",
      "torch.Size([1, 1])\n",
      "Example 4\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "torch.Size([1, 1])\n",
      "Example 5\n",
      "Input: [0, 1]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, input_sequence, max_length=15, SOS_token=2, EOS_token=3):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
    "    print(y_input.shape)\n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "  \n",
    "  \n",
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 3]], dtype=torch.long, device=device)\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {idx}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318457ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca796e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
